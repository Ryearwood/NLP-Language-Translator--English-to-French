{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wph3CfuAmfxY"
   },
   "source": [
    "## Import Libraries Needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "Y3T8lJSbmfxd"
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sfCp_Vrkmfxd"
   },
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run on Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YmGJRINHom8Z",
    "outputId": "762b7cbc-63a0-4f41-9210-d18f17052793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\r\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "mICtwQuPmfxe"
   },
   "outputs": [],
   "source": [
    "def load_data(input_file):\n",
    "   \n",
    "    with open(input_file, \"r\") as f:\n",
    "        data = f.read()\n",
    "\n",
    "    return data.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KgPQBh51mfxe",
    "outputId": "71632f7d-2774-4a0d-e850-e2328e5557d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Loaded\n"
     ]
    }
   ],
   "source": [
    "english_sentences = load_data('/content/drive/My Drive/Colab Notebooks/small_vocab_en.txt')\n",
    "french_sentences = load_data('/content/drive/My Drive/Colab Notebooks/small_vocab_fr.txt')\n",
    "print('Dataset Loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wP1Ie9yvmfxf"
   },
   "source": [
    "## Split Dataset into Train/Test Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H0DbPaUXmfxf"
   },
   "source": [
    "## Examine Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kWlb7fULmfxf",
    "outputId": "5cf540dd-0394-48bb-99bf-77bac1da6742"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1823250 English words.\n",
      "227 unique English words.\n",
      "10 Most common words in the English dataset:\n",
      "\"is\" \",\" \".\" \"in\" \"it\" \"during\" \"the\" \"but\" \"and\" \"sometimes\"\n",
      "\n",
      "1961295 French words.\n",
      "355 unique French words.\n",
      "10 Most common words in the French dataset:\n",
      "\"est\" \".\" \",\" \"en\" \"il\" \"les\" \"mais\" \"et\" \"la\" \"parfois\"\n"
     ]
    }
   ],
   "source": [
    "english_words_counter = collections.Counter([word for sentence in english_sentences for word in sentence.split()])\n",
    "french_words_counter = collections.Counter([word for sentence in french_sentences for word in sentence.split()])\n",
    "\n",
    "print('{} English words.'.format(len([word for sentence in english_sentences for word in sentence.split()])))\n",
    "print('{} unique English words.'.format(len(english_words_counter)))\n",
    "print('10 Most common words in the English dataset:')\n",
    "print('\"' + '\" \"'.join(list(zip(*english_words_counter.most_common(10)))[0]) + '\"')\n",
    "print()\n",
    "print('{} French words.'.format(len([word for sentence in french_sentences for word in sentence.split()])))\n",
    "print('{} unique French words.'.format(len(french_words_counter)))\n",
    "print('10 Most common words in the French dataset:')\n",
    "print('\"' + '\" \"'.join(list(zip(*french_words_counter.most_common(10)))[0]) + '\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qJdoXG7Rmfxf"
   },
   "source": [
    "## Data Pre-processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "2Yox1XWRmfxg"
   },
   "outputs": [],
   "source": [
    "# Tokenizing Function to transform\n",
    "def tokenize(sentence):\n",
    "    tokenizer = Tokenizer(char_level = False)\n",
    "    tokenizer.fit_on_texts(sentence)\n",
    "    return tokenizer.texts_to_sequences(sentence), tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "TYV0ctuRmfxg"
   },
   "outputs": [],
   "source": [
    "# Padding Function\n",
    "def pad(sentence, length=None):\n",
    "    if length is None:\n",
    "        length = max([len(sentence) for sentence in sentence])\n",
    "    return pad_sequences(sentence, maxlen = length, padding = 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Vatb5-ZJmfxg"
   },
   "outputs": [],
   "source": [
    "# Preprocessing pipeline function\n",
    "def preprocess(x, y):\n",
    "    \n",
    "    # Tokenize the input data\n",
    "    preprocess_x, x_tk = tokenize(x)\n",
    "    preprocess_y, y_tk = tokenize(y)\n",
    "    \n",
    "    #Pad the Tokenized data\n",
    "    preprocess_x = pad(preprocess_x)\n",
    "    preprocess_y = pad(preprocess_y)\n",
    "\n",
    "    # Keras's sparse_categorical_crossentropy function requires the labels to be in 3 dimensions\n",
    "    preprocess_y = preprocess_y.reshape(*preprocess_y.shape, 1)\n",
    "\n",
    "    return preprocess_x, preprocess_y, x_tk, y_tk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l5brbGOdmfxg"
   },
   "source": [
    "### Train Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2_v4fDBymfxg",
    "outputId": "52408816-4aae-4ccf-b2f1-45549169e0da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Preprocessed\n",
      "Train data: English vocab size - 137861\n",
      "Train data: French vocab size - 137861\n",
      "Max English sentence length: 15\n",
      "Max French sentence length: 21\n",
      "English vocab size: 199\n",
      "French vocab size: 344\n"
     ]
    }
   ],
   "source": [
    "# Run Preprocessing pipeline on Data\n",
    "processed_english_sentences, processed_french_sentences, eng_tokenizer, french_tokenizer = preprocess(english_sentences, french_sentences)\n",
    "\n",
    "# Get train data lengths and sizes\n",
    "max_english_sequence_length = processed_english_sentences.shape[1]\n",
    "max_french_sequence_length = processed_french_sentences.shape[1]\n",
    "english_vocab_size = len(eng_tokenizer.word_index)\n",
    "french_vocab_size = len(french_tokenizer.word_index)\n",
    "\n",
    "print('Train Data Preprocessed')\n",
    "print('Train data: English vocab size -', len(processed_english_sentences))\n",
    "print('Train data: French vocab size -', len(processed_french_sentences))\n",
    "print(\"Max English sentence length:\", max_english_sequence_length)\n",
    "print(\"Max French sentence length:\", max_french_sequence_length)\n",
    "print(\"English vocab size:\", english_vocab_size)\n",
    "print(\"French vocab size:\", french_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uDoE5sL_mfxh"
   },
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "LTraHRt0mfxh"
   },
   "outputs": [],
   "source": [
    "# RNN model incorporating Bidirectional and Embedding techniques in Neural network\n",
    "\n",
    "# Set Model Parameters and layers\n",
    "model = Sequential()\n",
    "# Embedding Layer\n",
    "model.add(Embedding(input_dim=len(eng_tokenizer.word_index)+1,\n",
    "                    output_dim=128,\n",
    "                    input_length=processed_english_sentences.shape[1]))\n",
    "# 1st Bidrectional layer - no feedback returned\n",
    "model.add(Bidirectional(GRU(256,return_sequences=False)))\n",
    "model.add(RepeatVector(processed_french_sentences.shape[1]))\n",
    "# 2nd Embedding layer - feedback returned\n",
    "model.add(Bidirectional(GRU(256,return_sequences=True)))\n",
    "model.add(TimeDistributed(Dense(len(french_tokenizer.word_index)+1,activation='softmax')))\n",
    "learning_rate = 0.005\n",
    "\n",
    "# Compile Model parameters\n",
    "model.compile(loss = sparse_categorical_crossentropy, \n",
    "              optimizer = Adam(learning_rate), \n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UUchAn8jmfxh",
    "outputId": "7256a651-c7a4-480f-fb87-fc78eba610fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1724/1724 [==============================] - 25s 14ms/step - loss: 0.5338 - accuracy: 0.8520 - val_loss: 0.6297 - val_accuracy: 0.8172\n",
      "Epoch 2/100\n",
      "1724/1724 [==============================] - 26s 15ms/step - loss: 0.5073 - accuracy: 0.8496 - val_loss: 0.5064 - val_accuracy: 0.8486\n",
      "Epoch 3/100\n",
      "1724/1724 [==============================] - 25s 15ms/step - loss: 0.6211 - accuracy: 0.8115 - val_loss: 0.6104 - val_accuracy: 0.8094\n",
      "Epoch 4/100\n",
      "1724/1724 [==============================] - 25s 15ms/step - loss: 0.6496 - accuracy: 0.7988 - val_loss: 0.8183 - val_accuracy: 0.7501\n",
      "Epoch 5/100\n",
      "1724/1724 [==============================] - 25s 15ms/step - loss: 0.8591 - accuracy: 0.7449 - val_loss: 0.7814 - val_accuracy: 0.7581\n",
      "Epoch 6/100\n",
      "1724/1724 [==============================] - 26s 15ms/step - loss: 0.8557 - accuracy: 0.7457 - val_loss: 0.8500 - val_accuracy: 0.7446\n",
      "Epoch 7/100\n",
      "1724/1724 [==============================] - 25s 15ms/step - loss: 0.8934 - accuracy: 0.7345 - val_loss: 1.0915 - val_accuracy: 0.6875\n",
      "Epoch 8/100\n",
      "1724/1724 [==============================] - 25s 15ms/step - loss: 1.0040 - accuracy: 0.7039 - val_loss: 0.9681 - val_accuracy: 0.7117\n",
      "Epoch 9/100\n",
      "1724/1724 [==============================] - 25s 14ms/step - loss: 1.1030 - accuracy: 0.6825 - val_loss: 1.1406 - val_accuracy: 0.6766\n",
      "Epoch 10/100\n",
      "1724/1724 [==============================] - 27s 15ms/step - loss: 1.1007 - accuracy: 0.6817 - val_loss: 1.1038 - val_accuracy: 0.6796\n",
      "Epoch 11/100\n",
      "1724/1724 [==============================] - 25s 14ms/step - loss: 1.0685 - accuracy: 0.6845 - val_loss: 1.0371 - val_accuracy: 0.6936\n",
      "Epoch 12/100\n",
      "1724/1724 [==============================] - 25s 15ms/step - loss: 1.0715 - accuracy: 0.6851 - val_loss: 1.1564 - val_accuracy: 0.6662\n",
      "Epoch 13/100\n",
      "1724/1724 [==============================] - 25s 15ms/step - loss: 1.1150 - accuracy: 0.6759 - val_loss: 1.1317 - val_accuracy: 0.6738\n",
      "Epoch 14/100\n",
      "1724/1724 [==============================] - 26s 15ms/step - loss: 1.1507 - accuracy: 0.6650 - val_loss: 1.2503 - val_accuracy: 0.6491\n",
      "Epoch 15/100\n",
      "1724/1724 [==============================] - 25s 15ms/step - loss: 1.3453 - accuracy: 0.6283 - val_loss: 1.2214 - val_accuracy: 0.6506\n",
      "Epoch 16/100\n",
      "1724/1724 [==============================] - 26s 15ms/step - loss: 1.2085 - accuracy: 0.6515 - val_loss: 1.1879 - val_accuracy: 0.6583\n",
      "Epoch 17/100\n",
      "1724/1724 [==============================] - 25s 15ms/step - loss: 1.1901 - accuracy: 0.6562 - val_loss: 1.1510 - val_accuracy: 0.6651\n",
      "Epoch 18/100\n",
      "1724/1724 [==============================] - 25s 14ms/step - loss: 1.1523 - accuracy: 0.6643 - val_loss: 1.1214 - val_accuracy: 0.6718\n",
      "Epoch 19/100\n",
      "1724/1724 [==============================] - 26s 15ms/step - loss: 1.1136 - accuracy: 0.6729 - val_loss: 1.1123 - val_accuracy: 0.6721\n",
      "Epoch 20/100\n",
      "1724/1724 [==============================] - 25s 15ms/step - loss: 1.1668 - accuracy: 0.6600 - val_loss: 1.1618 - val_accuracy: 0.6638\n",
      "Epoch 21/100\n",
      "1724/1724 [==============================] - 25s 15ms/step - loss: 1.1391 - accuracy: 0.6668 - val_loss: 1.1541 - val_accuracy: 0.6605\n",
      "Epoch 22/100\n",
      "1724/1724 [==============================] - 25s 14ms/step - loss: 1.1269 - accuracy: 0.6710 - val_loss: 1.1827 - val_accuracy: 0.6621\n",
      "Epoch 23/100\n",
      "1724/1724 [==============================] - 25s 15ms/step - loss: 1.1823 - accuracy: 0.6596 - val_loss: 1.1951 - val_accuracy: 0.6551\n",
      "Epoch 24/100\n",
      "1724/1724 [==============================] - 25s 15ms/step - loss: 1.2605 - accuracy: 0.6423 - val_loss: 1.1839 - val_accuracy: 0.6592\n",
      "Epoch 25/100\n",
      "1724/1724 [==============================] - 25s 14ms/step - loss: 1.1497 - accuracy: 0.6658 - val_loss: 1.1886 - val_accuracy: 0.6538\n",
      "Epoch 26/100\n",
      "1724/1724 [==============================] - 25s 15ms/step - loss: 1.1290 - accuracy: 0.6690 - val_loss: 1.0842 - val_accuracy: 0.6795\n",
      "Epoch 27/100\n",
      "1724/1724 [==============================] - 25s 14ms/step - loss: 1.1297 - accuracy: 0.6701 - val_loss: 1.1236 - val_accuracy: 0.6717\n",
      "Epoch 28/100\n",
      "1724/1724 [==============================] - 25s 15ms/step - loss: 1.1659 - accuracy: 0.6606 - val_loss: 1.2037 - val_accuracy: 0.6552\n",
      "Epoch 29/100\n",
      "1724/1724 [==============================] - 25s 15ms/step - loss: 1.2504 - accuracy: 0.6458 - val_loss: 1.2063 - val_accuracy: 0.6505\n",
      "Epoch 30/100\n",
      "1724/1724 [==============================] - 26s 15ms/step - loss: 1.1647 - accuracy: 0.6630 - val_loss: 1.2417 - val_accuracy: 0.6499\n",
      "Epoch 31/100\n",
      "1724/1724 [==============================] - 25s 15ms/step - loss: 1.3062 - accuracy: 0.6358 - val_loss: 1.2215 - val_accuracy: 0.6549\n",
      "Epoch 32/100\n",
      "1724/1724 [==============================] - 25s 15ms/step - loss: 1.2055 - accuracy: 0.6559 - val_loss: 1.3461 - val_accuracy: 0.6319\n",
      "Epoch 33/100\n",
      "1724/1724 [==============================] - 26s 15ms/step - loss: 1.1860 - accuracy: 0.6632 - val_loss: 1.1667 - val_accuracy: 0.6673\n",
      "Epoch 34/100\n",
      "1724/1724 [==============================] - 25s 15ms/step - loss: 1.1534 - accuracy: 0.6689 - val_loss: 1.2517 - val_accuracy: 0.6469\n",
      "Epoch 35/100\n",
      "1724/1724 [==============================] - 25s 15ms/step - loss: 1.1934 - accuracy: 0.6608 - val_loss: 1.2205 - val_accuracy: 0.6547\n",
      "Epoch 36/100\n",
      "1724/1724 [==============================] - 26s 15ms/step - loss: 1.2586 - accuracy: 0.6478 - val_loss: 1.2912 - val_accuracy: 0.6413\n",
      "Epoch 37/100\n",
      "1724/1724 [==============================] - 25s 14ms/step - loss: 1.2226 - accuracy: 0.6536 - val_loss: 1.1805 - val_accuracy: 0.6638\n",
      "Epoch 38/100\n",
      "1724/1724 [==============================] - 26s 15ms/step - loss: 1.1820 - accuracy: 0.6643 - val_loss: 1.1493 - val_accuracy: 0.6740\n",
      "Epoch 39/100\n",
      "1724/1724 [==============================] - 26s 15ms/step - loss: 1.1860 - accuracy: 0.6633 - val_loss: 1.2336 - val_accuracy: 0.6512\n",
      "Epoch 40/100\n",
      "1724/1724 [==============================] - 26s 15ms/step - loss: 1.2554 - accuracy: 0.6505 - val_loss: 1.2392 - val_accuracy: 0.6523\n",
      "Epoch 41/100\n",
      "1724/1724 [==============================] - 26s 15ms/step - loss: 1.2017 - accuracy: 0.6625 - val_loss: 1.3063 - val_accuracy: 0.6425\n",
      "Epoch 42/100\n",
      "1724/1724 [==============================] - 25s 14ms/step - loss: 1.2579 - accuracy: 0.6519 - val_loss: 1.3272 - val_accuracy: 0.6331\n",
      "Epoch 43/100\n",
      "1724/1724 [==============================] - 26s 15ms/step - loss: 1.2687 - accuracy: 0.6461 - val_loss: 1.2887 - val_accuracy: 0.6453\n",
      "Epoch 44/100\n",
      "1724/1724 [==============================] - 25s 15ms/step - loss: 1.2256 - accuracy: 0.6535 - val_loss: 1.2961 - val_accuracy: 0.6389\n",
      "Epoch 45/100\n",
      "1724/1724 [==============================] - 25s 15ms/step - loss: 1.2818 - accuracy: 0.6432 - val_loss: 1.3350 - val_accuracy: 0.6329\n",
      "Epoch 46/100\n",
      "1724/1724 [==============================] - 26s 15ms/step - loss: 1.2805 - accuracy: 0.6436 - val_loss: 1.2709 - val_accuracy: 0.6437\n",
      "Epoch 47/100\n",
      "1724/1724 [==============================] - 25s 15ms/step - loss: 1.2742 - accuracy: 0.6461 - val_loss: 1.3171 - val_accuracy: 0.6417\n",
      "Epoch 48/100\n",
      "1724/1724 [==============================] - 25s 14ms/step - loss: 1.2497 - accuracy: 0.6520 - val_loss: 1.2124 - val_accuracy: 0.6551\n",
      "Epoch 49/100\n",
      "1724/1724 [==============================] - 24s 14ms/step - loss: 1.2515 - accuracy: 0.6501 - val_loss: 1.2542 - val_accuracy: 0.6540\n",
      "Epoch 50/100\n",
      "1724/1724 [==============================] - 25s 14ms/step - loss: 1.2685 - accuracy: 0.6475 - val_loss: 1.2541 - val_accuracy: 0.6496\n",
      "Epoch 51/100\n",
      "1724/1724 [==============================] - 25s 14ms/step - loss: 1.2996 - accuracy: 0.6403 - val_loss: 1.3905 - val_accuracy: 0.6231\n",
      "Epoch 52/100\n",
      "1724/1724 [==============================] - 25s 14ms/step - loss: 1.2938 - accuracy: 0.6433 - val_loss: 1.2377 - val_accuracy: 0.6513\n",
      "Epoch 53/100\n",
      "1724/1724 [==============================] - 24s 14ms/step - loss: 1.2490 - accuracy: 0.6561 - val_loss: 1.2281 - val_accuracy: 0.6600\n",
      "Epoch 54/100\n",
      "1724/1724 [==============================] - 24s 14ms/step - loss: 1.2488 - accuracy: 0.6537 - val_loss: 1.3122 - val_accuracy: 0.6461\n",
      "Epoch 55/100\n",
      "1724/1724 [==============================] - 25s 14ms/step - loss: 1.2669 - accuracy: 0.6493 - val_loss: 1.2921 - val_accuracy: 0.6436\n",
      "Epoch 56/100\n",
      "1724/1724 [==============================] - 25s 14ms/step - loss: 1.2795 - accuracy: 0.6495 - val_loss: 1.2563 - val_accuracy: 0.6570\n",
      "Epoch 57/100\n",
      "1724/1724 [==============================] - 24s 14ms/step - loss: 1.2439 - accuracy: 0.6581 - val_loss: 1.2483 - val_accuracy: 0.6555\n",
      "Epoch 58/100\n",
      "1724/1724 [==============================] - 25s 15ms/step - loss: 1.2415 - accuracy: 0.6557 - val_loss: 1.2566 - val_accuracy: 0.6517\n",
      "Epoch 59/100\n",
      "1724/1724 [==============================] - 25s 14ms/step - loss: 1.2452 - accuracy: 0.6549 - val_loss: 1.2545 - val_accuracy: 0.6506\n",
      "Epoch 60/100\n",
      "1724/1724 [==============================] - 25s 14ms/step - loss: 1.3112 - accuracy: 0.6377 - val_loss: 1.2820 - val_accuracy: 0.6433\n",
      "Epoch 61/100\n",
      "1724/1724 [==============================] - 25s 14ms/step - loss: 1.3135 - accuracy: 0.6376 - val_loss: 1.2515 - val_accuracy: 0.6516\n",
      "Epoch 62/100\n",
      "1724/1724 [==============================] - 24s 14ms/step - loss: 1.3120 - accuracy: 0.6390 - val_loss: 1.3217 - val_accuracy: 0.6389\n",
      "Epoch 63/100\n",
      "1724/1724 [==============================] - 25s 14ms/step - loss: 1.3587 - accuracy: 0.6300 - val_loss: 1.3454 - val_accuracy: 0.6347\n",
      "Epoch 64/100\n",
      "1724/1724 [==============================] - 24s 14ms/step - loss: 1.3282 - accuracy: 0.6350 - val_loss: 1.3485 - val_accuracy: 0.6333\n",
      "Epoch 65/100\n",
      "1724/1724 [==============================] - 25s 14ms/step - loss: 1.3671 - accuracy: 0.6291 - val_loss: 1.4255 - val_accuracy: 0.6175\n",
      "Epoch 66/100\n",
      "1724/1724 [==============================] - 24s 14ms/step - loss: 1.3422 - accuracy: 0.6335 - val_loss: 1.3290 - val_accuracy: 0.6393\n",
      "Epoch 67/100\n",
      "1724/1724 [==============================] - 25s 14ms/step - loss: 1.3433 - accuracy: 0.6340 - val_loss: 1.3500 - val_accuracy: 0.6319\n",
      "Epoch 68/100\n",
      "1724/1724 [==============================] - 25s 14ms/step - loss: 1.3392 - accuracy: 0.6372 - val_loss: 1.4451 - val_accuracy: 0.6195\n",
      "Epoch 69/100\n",
      "1724/1724 [==============================] - 25s 14ms/step - loss: 1.3878 - accuracy: 0.6279 - val_loss: 1.4201 - val_accuracy: 0.6257\n",
      "Epoch 70/100\n",
      "1724/1724 [==============================] - 25s 14ms/step - loss: 1.3630 - accuracy: 0.6334 - val_loss: 1.3526 - val_accuracy: 0.6348\n",
      "Epoch 71/100\n",
      "1724/1724 [==============================] - 25s 15ms/step - loss: 1.2939 - accuracy: 0.6463 - val_loss: 1.2814 - val_accuracy: 0.6486\n",
      "Epoch 72/100\n",
      "1724/1724 [==============================] - 25s 14ms/step - loss: 1.3325 - accuracy: 0.6392 - val_loss: 1.3369 - val_accuracy: 0.6357\n",
      "Epoch 73/100\n",
      "1724/1724 [==============================] - 25s 15ms/step - loss: 1.3507 - accuracy: 0.6357 - val_loss: 1.3700 - val_accuracy: 0.6304\n",
      "Epoch 74/100\n",
      "1724/1724 [==============================] - 25s 14ms/step - loss: 1.3461 - accuracy: 0.6369 - val_loss: 1.3276 - val_accuracy: 0.6401\n",
      "Epoch 75/100\n",
      "1724/1724 [==============================] - 25s 14ms/step - loss: 1.3682 - accuracy: 0.6311 - val_loss: 1.4165 - val_accuracy: 0.6217\n",
      "Epoch 76/100\n",
      "1724/1724 [==============================] - 24s 14ms/step - loss: 1.3728 - accuracy: 0.6309 - val_loss: 1.3562 - val_accuracy: 0.6336\n",
      "Epoch 77/100\n",
      "1724/1724 [==============================] - 25s 14ms/step - loss: 1.3234 - accuracy: 0.6417 - val_loss: 1.3478 - val_accuracy: 0.6367\n",
      "Epoch 78/100\n",
      "1724/1724 [==============================] - 24s 14ms/step - loss: 1.3511 - accuracy: 0.6357 - val_loss: 1.3158 - val_accuracy: 0.6403\n",
      "Epoch 79/100\n",
      "1724/1724 [==============================] - 24s 14ms/step - loss: 1.2877 - accuracy: 0.6475 - val_loss: 1.3111 - val_accuracy: 0.6473\n",
      "Epoch 80/100\n",
      "1724/1724 [==============================] - 25s 15ms/step - loss: 1.3540 - accuracy: 0.6348 - val_loss: 1.3776 - val_accuracy: 0.6265\n",
      "Epoch 81/100\n",
      "1724/1724 [==============================] - 25s 14ms/step - loss: 1.3483 - accuracy: 0.6354 - val_loss: 1.2877 - val_accuracy: 0.6485\n",
      "Epoch 82/100\n",
      "1724/1724 [==============================] - 24s 14ms/step - loss: 1.3039 - accuracy: 0.6451 - val_loss: 1.2985 - val_accuracy: 0.6500\n",
      "Epoch 83/100\n",
      "1724/1724 [==============================] - 25s 15ms/step - loss: 1.2952 - accuracy: 0.6489 - val_loss: 1.2795 - val_accuracy: 0.6517\n",
      "Epoch 84/100\n",
      "1724/1724 [==============================] - 24s 14ms/step - loss: 1.3003 - accuracy: 0.6489 - val_loss: 1.2936 - val_accuracy: 0.6510\n",
      "Epoch 85/100\n",
      "1724/1724 [==============================] - 25s 14ms/step - loss: 1.2938 - accuracy: 0.6503 - val_loss: 1.2855 - val_accuracy: 0.6526\n",
      "Epoch 86/100\n",
      "1724/1724 [==============================] - 24s 14ms/step - loss: 1.3425 - accuracy: 0.6407 - val_loss: 1.3868 - val_accuracy: 0.6369\n",
      "Epoch 87/100\n",
      "1724/1724 [==============================] - 25s 15ms/step - loss: 1.3336 - accuracy: 0.6433 - val_loss: 1.3009 - val_accuracy: 0.6478\n",
      "Epoch 88/100\n",
      "1724/1724 [==============================] - 25s 15ms/step - loss: 1.3126 - accuracy: 0.6449 - val_loss: 1.2813 - val_accuracy: 0.6532\n",
      "Epoch 89/100\n",
      "1724/1724 [==============================] - 24s 14ms/step - loss: 1.3161 - accuracy: 0.6439 - val_loss: 1.3505 - val_accuracy: 0.6410\n",
      "Epoch 90/100\n",
      "1724/1724 [==============================] - 24s 14ms/step - loss: 1.3618 - accuracy: 0.6345 - val_loss: 1.3264 - val_accuracy: 0.6451\n",
      "Epoch 91/100\n",
      "1724/1724 [==============================] - 24s 14ms/step - loss: 1.3184 - accuracy: 0.6451 - val_loss: 1.3194 - val_accuracy: 0.6435\n",
      "Epoch 92/100\n",
      "1724/1724 [==============================] - 25s 14ms/step - loss: 1.3729 - accuracy: 0.6337 - val_loss: 1.3680 - val_accuracy: 0.6347\n",
      "Epoch 93/100\n",
      "1724/1724 [==============================] - 25s 14ms/step - loss: 1.3820 - accuracy: 0.6305 - val_loss: 1.3549 - val_accuracy: 0.6373\n",
      "Epoch 94/100\n",
      "1724/1724 [==============================] - 25s 14ms/step - loss: 1.3678 - accuracy: 0.6349 - val_loss: 1.3851 - val_accuracy: 0.6306\n",
      "Epoch 95/100\n",
      "1724/1724 [==============================] - 25s 14ms/step - loss: 1.3766 - accuracy: 0.6322 - val_loss: 1.3864 - val_accuracy: 0.6329\n",
      "Epoch 96/100\n",
      "1724/1724 [==============================] - 24s 14ms/step - loss: 1.3472 - accuracy: 0.6382 - val_loss: 1.2958 - val_accuracy: 0.6493\n",
      "Epoch 97/100\n",
      "1724/1724 [==============================] - 24s 14ms/step - loss: 1.3221 - accuracy: 0.6424 - val_loss: 1.3099 - val_accuracy: 0.6460\n",
      "Epoch 98/100\n",
      "1724/1724 [==============================] - 25s 14ms/step - loss: 1.3064 - accuracy: 0.6468 - val_loss: 1.3293 - val_accuracy: 0.6440\n",
      "Epoch 99/100\n",
      "1724/1724 [==============================] - 25s 14ms/step - loss: 1.3385 - accuracy: 0.6400 - val_loss: 1.3415 - val_accuracy: 0.6406\n",
      "Epoch 100/100\n",
      "1724/1724 [==============================] - 24s 14ms/step - loss: 1.3541 - accuracy: 0.6379 - val_loss: 1.3402 - val_accuracy: 0.6410\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb89a09d650>"
      ]
     },
     "execution_count": 133,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit Model on Data\n",
    "model.fit(processed_english_sentences,processed_french_sentences, batch_size = 64, epochs = 100, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BqqvSck9OWUD",
    "outputId": "dc82e2f7-9fd8-4fd6-8ca4-47339515e8e7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_55_layer_call_and_return_conditional_losses, gru_cell_55_layer_call_fn, gru_cell_56_layer_call_and_return_conditional_losses, gru_cell_56_layer_call_fn, gru_cell_58_layer_call_and_return_conditional_losses while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as gru_cell_55_layer_call_and_return_conditional_losses, gru_cell_55_layer_call_fn, gru_cell_56_layer_call_and_return_conditional_losses, gru_cell_56_layer_call_fn, gru_cell_58_layer_call_and_return_conditional_losses while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/Fitted_model_98%/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/Fitted_model_98%/assets\n"
     ]
    }
   ],
   "source": [
    "# Save the fitted model\r\n",
    "model.save('/content/drive/MyDrive/Colab Notebooks/Second_model_%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "id": "WtS-Ex6OQLTo"
   },
   "outputs": [],
   "source": [
    "# Load Fitted Model for use\r\n",
    "from tensorflow import keras\r\n",
    "model = keras.models.load_model('/content/drive/MyDrive/Colab Notebooks/Fitted_model_98%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "id": "mm0qLh5rmfxh"
   },
   "outputs": [],
   "source": [
    "def English_to_French(sentence):\n",
    "    \n",
    "    french_id_to_word = {value: key for key, value in french_tokenizer.word_index.items()}\n",
    "    french_id_to_word[0] = ''\n",
    "    x = sentence\n",
    "    # Get Id's for tokenized sentence\n",
    "    sentence = [eng_tokenizer.word_index[word] for word in sentence.split()]\n",
    "    # Pad Id's to uniform length\n",
    "    sentence = pad_sequences([sentence], maxlen=processed_english_sentences.shape[-1], padding='post')\n",
    "    # Predict french Id's using sentence Id's in Fitted Model\n",
    "    predictions = model.predict(sentence, len(sentence))\n",
    "  \n",
    "    print(x, \"in French:\")\n",
    "    print(' '.join([french_id_to_word[np.argmax(processed_english_sentences)] for processed_english_sentences in predictions[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_BOX9u-OkaL4",
    "outputId": "d2fb2b60-4042-4dc6-d2c6-705141e3f5b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he dislikes lemons grapes and mangoes in French:\n",
      "il d√©teste les citrons les raisins et les mangues            \n"
     ]
    }
   ],
   "source": [
    "phrase = 'he dislikes lemons grapes and mangoes'\r\n",
    "English_to_French(phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "id": "jiu-irCLmfxi",
    "outputId": "64c55094-2ce0-40fa-ddd1-85722229de81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Garbage collector: collected 289 objects.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "collected = gc.collect()\n",
    "print(\"Garbage collector: collected\",\"%d objects.\" % collected) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "puLAtdc0mfxi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1WBrhyNsmfxi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BPJL0tt9mfxi"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
